---
title: "Project - GROUP3"
output: 
  html_notebook:
    number_section: true
---

```{r setup, include=TRUE, echo=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::knit_hooks$set(document = function(x) {
    paste(rapply(strsplit(x, '\n'), function(y) Filter(function(z) !grepl('# HIDE',z),y)), collapse ='\n')
})
```

```{r load functions, echo=FALSE}
source(paste(getwd(), '/src/utilities.R', sep = ""))
source(paste(getwd(), '/src/functions.R', sep = ""))
```

# First Part
## Load the data in R

```{r load data, results='hold', collapse=TRUE}
{# HIDE
DATA   <- read.table(getRawPath("E-GEOD-76987-raw-counts.tsv"), sep = "\t", row.names = 1, header = TRUE)
LABELS <- read.delim(getRawPath("labels.txt"), sep = "\t", header = TRUE)
}# HIDE
```

## Calculate the sequencing depth of each sample

```{r calculate depth, results='hold', collapse=TRUE}
genes   <- DATA[,1]                 # name of the genes
samples <- DATA[,2:ncol(DATA)]      # samples in the datasets

genes_number   <- length(genes)     # it's the same of using -> nrow(samples)       
samples_number <- length(samples)   # it's the same of using -> ncol(samples)


# Computing the sequencing depth of each sample

depth <- apply(samples, 2, sum)     # 2 means that we're appling the sum by columns

{# HIDE
cat("Our dataset is composed by:\n\n")
cat(paste("♦", genes_number, "genes\n", sep = " "))           
cat(paste("♦", samples_number, "samples\n\n", sep = " "))          

# cat("The sequencing depth of each sample is:\n", depth)

}# HIDE

```

## Produce the MvA plots of each sample vs. sample 1 (or another sample of your choice)

TODO: decide with respect to which sample we produce the plots and decide if remove the first column at the beginning or not

```{r generate temp dataset}
temp_samples <- samples + 1 # add 1 to all elements to avoid the log(0)
#TODO: save the temporary datasets into data/temp and reload it

extracted_index <- 1
    
interval <- (1:samples_number)[-extracted_index]
```

```{r produce MvA plots}
A <- matrix(0, nrow = genes_number, ncol = 0)
M <- matrix(0, nrow = genes_number, ncol = 0)

produceMvA(temp_samples, extracted_index, interval,  folder = "MvA", graph_title = "MvA Plot")
```

## - Implement the TMM and the quantile normalization

```{r TMM Normalization Implementation}
tmm_normalization
```

```{r Quantile Normalization Implementation}
quantile_normalization
```

## Normalize the data using the method of your choice (explaining the reason of your choice)
```{r TMM Normalization}
A <- matrix(0, nrow = genes_number, ncol = 0)
M <- matrix(0, nrow = genes_number, ncol = 0)

tmm_normed <- tmm_normalization(temp_samples, extracted_index, interval)

```

```{r Quantile normalization}
A <- matrix(0, nrow = genes_number, ncol = 0)
M <- matrix(0, nrow = genes_number, ncol = 0)

quantile_normed <- quantile_normalization(temp_samples)

```

<!-- explanation of our choice -->
We decided to use the quantile normalization; in fact, this type of normalization seemed more robust and gave better results. In fact, if we look at the MvA plots of sample 1 (the reference) VS sample 12, we can see that in the quantile normalization plot the cloud of points is more or less lying on M=0, as it should, while in the TMM normalization plot the cloud of points is clearly hanging below M=0. 

It is to be noted that neither the quantile nor the TMM normalization get rid of the "V-shaped" outliers near low values of A (average). The code below shows what was said here. 

```{r MvA plot of reference sample (sample 1) VS sample 12 with TMM and quantile normalization}

# Quantile
par(mfrow=c(1,2)) 
extracted <- quantile_normed$samples[,1]
selected  <- quantile_normed$samples[,12]
computed  <- MA(extracted, selected)
    
M <- cbind(M, computed$M) # equivalent to do computed[[1]]
A <- cbind(A, computed$A) # equivalent to do computed[[2]]
    
    
plot(computed$A, computed$M, xlab="A", ylab="M", main = "MvA plot - quantile", sub = paste("Sample", 1, "vs.", 12, sep = " "))
abline(0,0)

# TMM
extracted <- tmm_normed$samples[,1]
selected  <- tmm_normed$samples[,12]
computed  <- MA(extracted, selected)
    
M <- cbind(M, computed$M) # equivalent to do computed[[1]]
A <- cbind(A, computed$A) # equivalent to do computed[[2]]
    
    
plot(computed$A, computed$M, xlab="A", ylab="M", main = "MvA plot - TMM ", sub = paste("Sample", 1, "vs.", 12, sep = " "))
abline(0,0)

```

## Produce the MvA plots of each sample vs. sample 1 (or another sample of your choice) using normalized data to evaluate if the normalization step was correctly performed or if there are outlier samples.

```{r Produce Normalized MvA Plots}
{# HIDE
# TMM Normalization 
produceMvA(tmm_normed$samples, extracted_index, interval,  folder = "MvA - TMM Normalization", graph_title = "MvA (TMM Normalization)")

# Quantile Normalization
produceMvA(quantile_normed$samples, extracted_index, interval,  folder = "MvA - Quantile Normalization", graph_title = "MvA (Quantile Normalization)")
}# HIDE
```

<div style="text-align: justify">
You can see MvA plots inside output/plots folder, in particular you can notice that in some of them it's clear what was explained above with reference sample vs. sample 12. For example in reference sample vs. sample 47 plot the same comments can be made: MvA plots clearly show a deviance from M = 0 in TMM normalization while this deviance is not present in quantile normalization. This gives credit to the idea that quantile normalization is more robust because it produces a series of sample with the same distribution, while TMM normalization just takes care of the most evident outliers, because it uses a trimmed mean approach.
</div>

# Second Part

### Note 1 - There can be the same sample measured twice for a specific subject. We decided to take care of it by simply using a mean approach: the samples coming from a same subject in the same group (for istance subject 1 is measured two times as a control subject) are mediated.

```{r remove of the duplicates}
normal <- LABELS[LABELS$sample_type == c("normal"),]            # get all the normal samples
unimuc <- LABELS[LABELS$sample_type == c("uninvolved mucosa"),] # get all the uninvolved mucosa samples

control <- rbind(normal, unimuc)                                # concatenate them 
control <- control[order(as.numeric(control$individual)),]        # sort in function of 'individual' value

disease <- LABELS[LABELS$sample_type == c("colon sessile serrated adenoma/polyp"),] # get all the disease samples

control_nodup <- remove_duplicates(quantile_normed$samples, control) # remove duplicates in control
disease_nodup <- remove_duplicates(quantile_normed$samples, disease) # remove duplicates in disease
```

### Note 2 - There can be some genes that in both groups 1 and 2 have always expression equal to 0. We took care of this problem by taking out genes that had expression always equal to zero in all samples from the control group and the disease group. For instace, say that we look at gene 1: if the sum of the read counts for gene 1 in all the samples coming from control group is zero as it is in all the samples from the disease group then we can say that gene 1 has always expression zero, so it does not give information about differentially expressed genes in disease VS control groups. Gene 1 in this example is therefore taken out.

```{r taking care of zeros}
groups_nozero <- remove_zeros(control_nodup, disease_nodup)
control_nodup_nozero<-groups_nozero$control
disease_nodup_nozero<-groups_nozero$disease
```

## Calculate p-values of DE analysis (not corrected for multiple testing) between the two groups using t-test, Wilcoxon test and edgeR.

```{r p-values}
Nc<-nrow(control_nodup_nozero)
c_ttest_pvalue <- NULL
c_wilcoxon_pvalue <- NULL

selected_ttest<-0
selected_wilcox<-0
for(i in (1:Nc)){ 
  c_ttest_pvalue <- c(c_ttest_pvalue,t.test(control_nodup_nozero[i,], disease_nodup_nozero[i,], var.equal = FALSE)$p.value)
  c_wilcoxon_pvalue <- c(c_wilcoxon_pvalue,wilcox.test(control_nodup_nozero[i,],disease_nodup_nozero[i,], exact=FALSE)$p.value)
}
```

TODO: controllare nomi variabili

```{r preprocessing}
#Rebuilt control matrix with initial data (not normalized); this is done because edgeR was created to work with data whose distribution is negative binomial, as our initial data matrix. On the other hand, normalized data does not comply to negative binomial distribution, so it cannot be used as input for edgeR functions. 


control_nodup <- remove_duplicates(DATA, control)
control_nodup <- renameColumns(control_nodup, "control")
# count<-ncol(control_nodup)
# 
# nomi<-rep("", count)
# for (i in (1:count)) {
#   x<-paste("control",as.character(i),sep='_')
#   nomi[i]<-x
# }
# colnames(control_nodup)<-nomi




#Rebuilt disease matrix with initial data (not normalized)

disease_nodup <- remove_duplicates(DATA, disease)
disease_nodup <- renameColumns(control_nodup, "disease")

# count<-ncol(disease_nodup)
# nomi<-rep("", count)
# for (i in (1:count))
# {
#   x<-paste("disease",as.character(i),sep='_')
#   nomi[i]<-x
# }
# colnames(disease_nodup)<-nomi
```

TODO: controllare i commenti da lasciare, i nomi delle variabili e ciò da mostrare in output

```{r edgeR}
library(edgeR)

#unite the 2 tables 
mat <- cbind(disease_nodup, control_nodup)

#create groups
control_group <- rep("control",dim(control_nodup)[2])
disease_group <- rep("disease",dim(disease_nodup)[2])

#merge group; it will be input of factor()
group_all <- cbind(t(as.data.frame(disease_group)),t(as.data.frame(control_group)))

#use factor(): we get an object divided in 2 level (control and disease)
group <- factor(group_all)

# design matrix
design <- model.matrix(~0+group) 
rownames(design) <- colnames(mat)  


# fit values of phi (we need this step to fit our GLM model)
y  <- DGEList(counts=mat, remove.zeros = TRUE)    
y  <- calcNormFactors(y)   # scaling factors with TMM approach
SF <- y$samples

y <- estimateGLMCommonDisp(y,design, verbose=TRUE) #phi common to the entire dataset
y <- estimateGLMTrendedDisp(y,design) #phi depends on mu
y <- estimateGLMTagwiseDisp(y,design) #phi is gene specific
fit <- glmFit(y,design) # the model fit 


#the test
Confr<-makeContrasts(Treatment=groupdisease-groupcontrol,levels=design)
RES<-glmLRT(fit,contrast=Confr[,"Treatment"])

#some outputs just to give an idea of the test

RES$table[1:5,]


```

## Calculate the expected number of false positives (FP) and false negatives (FN) in correspondence to the choice of alpha = 0.05 and consider G0 = N with N being the number of genes.

```{r selection for alpha 0.05}
alpha<-0.05

lower<-(c_ttest_pvalue<alpha)
selected_ttest<-which(lower==TRUE)
num_sel_ttest<-length(selected_ttest)

lower<-(c_wilcoxon_pvalue<alpha)
selected_wilcox<-which(lower==TRUE)
num_sel_wilcox<-length(selected_wilcox)

#selected usando edgeR 
indSELedgeR<-length(which(out$PValue<alpha)) #i selected
```

```{r calculation of expected values}
G<-nrow(control_nodup_nozero)
G0<-G

#function that returns a vector with, in order, TP FP TN FN
expected_ttest <- expected_values(G, G0, alpha, num_sel_ttest)
expected_wilcoxontest <- expected_values(G, G0, alpha, num_sel_wilcox)
expected_edger <- expected_values(G, G0, alpha, indSELedgeR)
```

## Estimate the number of not differentially expressed genes G0 and re-estimate the expected number of false positives and false negatives.

``` {r estimation of G0 and re-estimation of the values for each test}
res <- estimateG0(c_ttest_pvalue, G0, "T test")
lambda_est_ttest <- 0.8
eps<-0.03
G0_est_ttest<-G0_value_estimation(lambda_est_ttest, eps, res)

expected_ttest_est <- expected_values(G, G0_est_ttest, alpha, num_sel_ttest)

res <- estimateG0(c_wilcoxon_pvalue, G0, "Wilcoxon test")
lambda_est_wilcoxon <- 0.8
eps<-0.03
G0_est_wilcoxontest<-G0_value_estimation(lambda_est_wilcoxon, eps, res)

expected_wilcoxontest_est <- expected_values(G, G0_est_wilcoxontest, alpha, num_sel_wilcox)

res <- estimateG0(out[,4], G0, "edgeR test")
lambda_est_edger <- 0.8
eps<-0.03
G0_est_edger<-G0_value_estimation(lambda_est_edger, eps, res)

expected_edgeR_est <- expected_values(G, G0_est_edger, alpha, indSELedgeR)

print("TP, FP, TN, FN with edgeR (using estimated G0)")
print(expected_edgeR_est)
print("TP, FP, TN, FN with t-test (using estimated G0)")
print(expected_ttest_est)
print("TP, FP, TN, FN with wilcoxon test (using estimated G0)")
print(expected_wilcoxontest_est)
```

## Choose the “best” test among t-test, Wilcoxon test and edgeR motivating your choice.

We chose edgeR for a few reasons; first of all, edgeR test was built for data with negative binomial distribution, while the other tests do not take into account the characteristics of this particular distribution. Then, it must also be said that it gives the lowest FN rate; while FP rate can be easily taken into account with a correction for multiple test, FN rate is not accounted for with this type of correction; the test must take into account FN rate. To conclude, we chose edgeR on the basis of the theory behind and also given the FP and FN rates.

## Select the final list of DE genes using the test chosen at point 4 and a false discovery rate threshold of 5%.

```{r select the final list of DE genes}
FDR <- 0.05
#values observed as p-value in edgeR (chosen test)
lambda<-seq(min(out[,4]), max(out[,4]), (max(out[,4])-min(out[,4]))/nrow(out))
FDR_values<-NULL

for (i in (1:length(lambda))) {
  #compute FDR for every lambda
  minori<-(out[,4]<lambda[i])
  num_sel<-length(which(minori==TRUE))
  
  expected_val <- expected_values(G, G0_est_edger, lambda[i], num_sel)
  
  if (num_sel==0){
    FDR_values<-c(FDR_values,0)} 
  else {
    FDR_values<-c(FDR_values,(expected_val[2]/num_sel))}
}

plot(lambda,FDR_values)

#choose the values that are in [0.05-epsilon;0.05+espilon]
epsilon <- 0.0001
alpha_index <- which(FDR_values>=0.05-epsilon)
alpha_index2 <- which(FDR_values<=0.05+epsilon)
alpha_est <- mean(lambda[intersect(alpha_index,alpha_index2)])

indexes<-which(out$PValue<alpha_est) #the ones selected
index_genes_selected<-sort(as.numeric(rownames(out[indexes,])))

ID_genes_selected<-rownames(DATA[index_genes_selected,])
number_genes_selected<-length(ID_genes_selected)
ID_genes_notselected <- setdiff(rownames(DATA),ID_genes_selected)
number_genes_notselected<-length(ID_genes_notselected)
```

# Third Part

## Extract G0 term associated 
We found out that some names of genes were duplicated but not their ENSEMBL IDs; so we used these IDs to get the annotation and extrct the right GO terms asociated with the genes. We also decided to take out those genes whose GOALL was NA, because this means that we don't have their associated term as of right now (the association is not complete in the DB).

```{r extract GO terms}


library(AnnotationDbi)
library(GO.db)
library(org.Hs.eg.db)

alldata <- select(org.Hs.eg.db, ID_genes_selected, columns = c("SYMBOL","ENTREZID", "ENSEMBL","GOALL"), keytype="ENSEMBL")
GOALL_NA<-which(is.na(alldata$GOALL))
ID_goall_na<-alldata$ENSEMBL[GOALL_NA]
GOALL_NA<-unique(GOALL_NA)

terms <- unique(alldata[,4])
terms <- terms[!is.na(terms)]

#get all the IDs for selected genes which are annotated in the DB (the genes for which we have the annotation in the DB); to improve computation, we also took out all the IDs of genes annotated but not selected and their respective total numbers. 
ID_genes_selected_notna <- setdiff(ID_genes_selected,ID_goall_na)
number_genes_selected_notna <- length(ID_genes_selected_notna)
ID_genes_notselected_notna <- setdiff(ID_genes_notselected,ID_goall_na)
number_genes_notselected_notna <- length(ID_genes_notselected_notna)


matrixes <- NULL

for (i in (1:length(terms))){
  GOterm <- terms[i]
  GOterm_indexes <- which(alldata$GOALL==GOterm)
  a <- length(intersect(alldata[GOterm_indexes,1],ID_genes_selected_notna))
  b <- number_genes_selected - a
  c <- length(GOterm_indexes) - a
  d <- length(ID_genes_notselected_notna)- c
  type<-alldata[(which(alldata[,4]==GOterm))[1],6]
  
  
  #this matrix has on rows the associated GO terms and on columns the type of GOterm and the values for computing the fisher test.
  matrixes <- rbind(matrixes,c(type,a,b,c,d))
}

colnames(matrixes)<-c("type","a","b","c","d")
rownames(matrixes)<-terms
matrixes<-matrixes[order(rownames(matrixes)),]

```
## Fisher test

```{r fisher test}


matrixesCC <- matrixes[which(matrixes[,1]=="CC"),]
colnames(matrixesCC)<-c("type","a","b","c","d")
matrixesBP <- matrixes[which(matrixes[,1]=="BP"),]
colnames(matrixesBP)<-c("type","a","b","c","d")
matrixesMF <- matrixes[which(matrixes[,1]=="MF"),]
colnames(matrixesMF)<-c("type","a","b","c","d")

pval_fisherCC<-fisher_test_matrixes(matrixesCC)
pval_fisherBP<-fisher_test_matrixes(matrixesBP)
pval_fisherMF<-fisher_test_matrixes(matrixesMF)
```

# Fourth Part 
### correcting for length of genes before clustering; we also decided to consider as one sample those samples taken for the same subject in the same group, as we did for testing the DE genes.
```{r init clustering}


library (EDASeq)
ensembl_list <- ID_genes_selected
d<-getGeneLengthAndGCContent(ensembl_list, "hsa")
#d[[1]] has the length of all genes selected

#prepare the matrix needed to normalize for length of genes
data_normalized<-DATA[,-1]
data_normalized<-data_normalized[index_genes_selected,]
data_normalized<-t(t(data_normalized)/d[[1]])



dataNorm_nodup_control<-remove_duplicates(data_normalized,control) 
dataNorm_nodup_disease<-remove_duplicates(data_normalized,disease) 

dataNorm_clustering<-cbind(dataNorm_nodup_control,dataNorm_nodup_disease)
```

## Cluster the genes you have selected in exercise 2 using k-means and hierarchical clustering and compare the results you obtain.

```{r clustering genes}
#CLUSTERING GENES kmeans

K<-seq(1,3,by=1)
WITHIN_SS<-NULL
clus_km<-NULL
sk <- NULL
for(i in (1:length(K)))
{
  k_i<-K[i]
  cl_kmeans_genes<-kmeans(x=dataNorm_clustering,centers=k_i,iter.max=100,nstart=1)
  clus_km<-c(clus_km,cl_kmeans_genes)
  WITHIN_SS<-rbind(WITHIN_SS, cl_kmeans_genes$tot.withinss)
  sk <- rbind(sk, silhouette(dataNorm_clustering,cl_kmeans_genes[[1]], k_i))
}
print(sk)
cat("K-Means over samples!\n")
print(sk)
cat(max(sk), " - optimal number of clusters is :", K[which(sk == max(sk))])
plot(K, WITHIN_SS)


#CLUSTERING GENES hierachical
D<-dist(dataNorm_clustering) 

#we chose ward.D2 as a method of clustering because it uses the euclidean distance; in this way we have a better way of comparison with k-means, which also uses euclidean distance
cl_hclust_ward<-hclust(d=D,method="ward.D2")
plot(cl_hclust_ward, hang=-1) 

sk <- NULL
K<-seq(1,10,by=1)
for (i in (1:length(K))){
  k <- K[i]
  clusters_hclust_ward<-cutree(cl_hclust_ward, k=k)
  sk <- c(sk,silhouette(dataNorm_clustering,clusters_hclust_ward,k))
  #print("i: ",i," - sk: ",sk)
}
cat("Hierarchial clusters over genes!\n")
print(sk)
cat(max(sk), " - optimal number of clusters is :", K[which(sk == max(sk))])



```


## Cluster the samples in your dataset (considering only the genes you have selected in exercise 2) using k-means and hierarchical clustering and compare the results you obtain

```{r clustering samples}
#CLUSTERING SAMPLES kmeans
K<-seq(1,10,by=1)
WITHIN_SS_sample<-NULL
clus_km_sample<-NULL
sk <- NULL
for(i in (1:length(K))) {
  k_i<-K[i]
  cl_kmeans_samples<-kmeans(x=t(dataNorm_clustering),centers=k_i,iter.max=100,nstart=100)
  clus_km_sample<-c(clus_km_sample,cl_kmeans_samples)
  WITHIN_SS_sample<-rbind(WITHIN_SS_sample, cl_kmeans_samples$tot.withinss)
  sk <- rbind(sk, silhouette(t(dataNorm_clustering),cl_kmeans_samples[[1]], k_i))
}
cat("K-Means over samples!\n")
print(sk)
cat(max(sk), " - optimal number of cluster is :", K[which(sk == max(sk))])
plot(K, WITHIN_SS_sample)

#CLUSTERING SAMPLES hierachical
D<-dist(t(dataNorm_clustering)) 

cl_hclust_ward_S<-hclust(d=D,method="ward.D2")
plot(cl_hclust_ward_S, hang=-1) 

sk <- NULL
K<-seq(1,10,by=1)
for (i in (1:length(K))){
  k <- K[i]
  clusters_hclust_ward_S<-cutree(cl_hclust_ward_S, k=k)
  sk <- c(sk,silhouette(t(dataNorm_clustering),clusters_hclust_ward_S,k))
}
cat("Hierarchial clusters over samples!\n")
print(sk)
cat(max(sk), " - optimal number of clusters is :", K[which(sk == max(sk))])

```

## Choose the optimal number of clusters using the silhouette statistic. Do not use available R functions, I want you to implement it.

```{r silhouette implementation}
silhouette
```
## Choose the optimal number of clusters using the Gap statistic. In this case you can use the R function clusGap() in the library “cluster”

```{r gap}
#GAP STATISTIC 
library(cluster)

test_hclust <- function(x, k) list(cluster=cutree(hclust(dist(x), method = "average"),k=k))

#SAMPLES
prova<-clusGap(t(dataNorm_clustering), test_hclust, length(K), B=100)

for (i in (2:(nrow(prova[[1]])-1))){
  if (prova[[1]][i,3]>prova[[1]][i+1,3]+prova[[1]][i+1,4])
    break;
}
cat("Numero ottimo per hierachical clustering dei samples secondo Gap Statistics: ",i)

#GENES
prova<-clusGap(dataNorm_clustering, test_hclust, length(K), B=100)

for (i in (1:(nrow(prova[[2]])-1))){
  if (prova[[1]][i,3]>prova[[1]][i+1,3]+prova[[1]][i+1,4])
    break;
}
cat("Numero ottimo per hierachical clustering dei geni secondo Gap Statistics: ",i)

# ---------------

#SAMPLES

test_kmeans <- function(x, k) (kmeans(x=x,centers=k,iter.max=100,nstart=100))

prova<-clusGap(t(dataNorm_clustering), test_kmeans, length(K), B=100)

for (i in (2:(nrow(prova[[1]])-1))){
  if ((prova[[1]][i,3])>(prova[[1]][i+1,3]+prova[[1]][i+1,4]))
    break;
}
cat("Numero ottimo per kmeans dei samples secondo Gap Statistics: ",i)

#GENES

prova<-clusGap(dataNorm_clustering, test_kmeans, length(K), B=2)

for (i in (2:(nrow(prova[[1]])-1))){
  if ((prova[[1]][i,3])>(prova[[1]][i+1,3]+prova[[1]][i+1,4]))
    break;
}
cat("Numero ottimo per kmeans dei geni secondo Gap Statistics: ",i)
```


```{r plots of part4, HIERARCHICAL}
# GENES, HIERARCHICAL CLUSTERING
library(factoextra)

nodePar <- list(lab.cex = 0.6, pch = NA)
hcd_G <- as.dendrogram(cl_hclust_ward)

#par(mfrow=c(3,1))
hcd<-as.dendrogram(cl_hclust_ward)
plot(cut(hcd, h=400)$upper, main="Upper tree of cut at h=400", nodePar = nodePar,
     leaflab = "textlike")

plot(cut(hcd, h=400)$lower[[2]], nodePar = nodePar, leaflab = "none",
     main="Second branch of lower tree with cut at h=400")

# SAMPLES, HIERARCHICAL CLUSTERING
hcd_S <- as.dendrogram(cl_hclust_ward_S)
plot(hcd_S, type = "rectangle", horiz = TRUE, xlab = "Height", nodePar = nodePar, leaflab = "none", main="Hierarchical clustering of samples")

```

```{r plot of part 4, kmeans}
#GENES, KMEANS
library(factoextra)
cl_genes<-kmeans(x=dataNorm_clustering, centers = 2, iter.max = 100, nstart = 100)
fviz_cluster(cl_genes, data = dataNorm_clustering,
             palette = c("#2E9FDF", "#00AFBB"), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw(),
             main="Kmeans clustering of genes"
)

#SAMPLES, KMEANS
cl_samples<-kmeans(x=t(dataNorm_clustering), centers = 3, iter.max = 100, nstart = 100)
fviz_cluster(cl_samples, data = t(dataNorm_clustering),
             palette = c("#2E9FDF", "#00AFBB", "#E7B800"), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw(),
             main="Kmeans clustering of samples"
)
```

