---
title: "GROUP3"
output:
  html_notebook:
    number_section: yes
  html_document:
    df_print: paged
---

```{r setup, include=TRUE, echo=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::knit_hooks$set(document = function(x) {
    paste(rapply(strsplit(x, '\n'), function(y) Filter(function(z) !grepl('# HIDE',z),y)), collapse ='\n')
})
```

```{r libraries, include = TRUE, echo = FALSE}
library(factoextra)
library(kableExtra)

library(FactoMineR)
library(dendextend)
library(ggpubr)
library(gridExtra)

library(edgeR)

library(AnnotationDbi)
library(GO.db)
library(org.Hs.eg.db)

library(EDASeq)

library(cluster)

library(caret)
library(e1071)
```

```{r load functions, echo=FALSE}
source(paste(getwd(), '/src/utilities.R', sep = ""))
source(paste(getwd(), '/src/functions.R', sep = ""))
```

# First Part

## Load the data

```{r load data, results='hold', collapse=TRUE}
{# HIDE
DATA   <- read.table(getRawPath("E-GEOD-76987-raw-counts.tsv"), sep = "\t", row.names = 1, header = TRUE)
LABELS <- read.delim(getRawPath("labels.txt"), sep = "\t", header = TRUE)
}# HIDE
```

## Calculate the sequencing depth of each sample

```{r calculate depth, results='hold', collapse=TRUE}
# extract information about data
genes <- DATA[,1]                
samples <- DATA[,2:ncol(DATA)]
genes_number <- length(genes)         
samples_number <- length(samples)   

# Computing the sequencing depth of each sample

depth <- apply(samples, 2, sum)     # 2 means that we're appling the sum by columns

{# HIDE
cat("Our dataset is composed by:\n\n")
cat(genes_number, " genes\n")           
cat(samples_number, "samples\n\n")

cat("The sequencing depth of each sample is:\n", depth)

cat("\nThe average depth is:", mean(depth))
}# HIDE
```

## Produce the MvA plots of each sample vs. sample 1 

<div style="text-align: justify">
We decided to use the first sample as reference because we noticed that there was not any significant difference between plots with other references. We added 1 to each value in the data matrix to avoid the log(0) computation in the following analysis.
</div>

```{r generate temp dataset}
temp_samples <- samples + 1

extracted_index <- 1
    
interval <- (1:samples_number)[-extracted_index]
```

<div style="text-align: justify">
The following function computes the intensity ratio and the average intensity of the vectors distribution in input by definition and return a list of them. The second function receives in input a matrix, the reference column index, the interval used to scan other samples, eventually a folder in which plots will be saved and the graph title. It computes M and A thanks to the MA function and plots the results.
</div>

```{r MA function}
MA
```

```{r produceMvA function}
produceMvA
```

```{r produce MvA plots, eval = FALSE}
produceMvA(temp_samples, extracted_index, interval,  folder = "MvA", graph_title = "MvA Plot")
producePlots(temp_samples, extracted_index, interval, folder = "Other")
```


<div style="text-align: justify">
In the following chunks, thanks to the PCA function we extract the first 10 PCs from the data with respect to samples and genes; the "cos2" coloration  is used to highlight the importance of a certain observation on the calculation of the given PC. We can also see thanks to the Scree plot that the maximum variation in the data is captured within the first component, as we expected.
</div>


```{r compute PCA samples, results='hide',fig.width=7, fig.height=7}
# PCA for samples
s_pca <- PCA(t(temp_samples), scale.unit = FALSE, ncp = 10, graph = FALSE)
p1 <- fviz_pca_ind(s_pca, col.ind = 'cos2', geom = 'point', title = 'PCA (Samples)')
p2 <- fviz_eig(s_pca)

grid.arrange(p1,p2)
```

```{r compute PCA genes, results='hide',fig.width=7, fig.height=7}
# PCA for genes
g_pca <- PCA(temp_samples, scale.unit = FALSE, ncp = 5, graph = FALSE)
p1 <- fviz_pca_ind(g_pca, col.ind = 'cos2', geom = 'point', title = 'PCA (Genes)')
p2 <- fviz_eig(g_pca)

grid.arrange(p1,p2)
```

## Implement the TMM and the quantile normalization

<div style="text-align: justify">
The following function implements the Trimmed-Mean Normalization. It receives in input a matrix x with samples in columns and genes in rows, a reference index of the reference subject with respect to which we perform normalization and an interval through which we scan all the other genes. For each gene except for the reference, it computes the MA values with respect to that reference, calculates the scaling factor as the trimmed mean of M values and does the normalization adding the scaling factor as exponential in base 2 to the current gene. 
</div>

```{r TMM Normalization Implementation}
tmm_normalization
```

<div style="text-align: justify">
The following function implements the Quantile Normalization. It receives in input the matrix x with samples in columns and genes in rows for which it computes the quantile normalization as defined in theory lessons. The setup matrixes for indexes, sorted values and for normed values are created; then, for each subject, the gene raw counts of that subject are sorted and given a rank usign the average method to deal with ties. Ranks will be used as indexes. Then, the mean by row is calculated on the matrix with sorted columns. At last,column by column,  the normalized matrix is built using the indexes from the ranking function to choose which mean values should be put in which positions. 
The quantile normalization return a matrix whose columns have all the same distribution. 
</div>

```{r Quantile Normalization Implementation}
quantile_normalization
```

## Normalize the data using the method of your choice

```{r TMM Normalization}
tmm_normed <- tmm_normalization(temp_samples, extracted_index, interval)
```

```{r Quantile normalization}
quantile_normed <- quantile_normalization(temp_samples)
```

```{r Normalization Plots, fig.width=12, fig.height=5}
par(mfrow=c(1,3)) 


plot(samples[,1], samples[,12], pch=20, cex=2,  col="#3185FC",xlab="Sample 1", ylab="Sample 12", main = "Samples")
abline(0, 1, col = "red")

extracted <- tmm_normed$samples[,1]
selected  <- tmm_normed$samples[,12]


plot(extracted, selected, pch=20, cex=2,  col="#3185FC", xlab="Sample 1", ylab="Sample 12", main = "Samples (TMM)")
abline(0, 1, col = "red")


extracted <- quantile_normed$samples[,1]
selected  <- quantile_normed$samples[,12]
plot(extracted, selected, pch=20, cex=2,  col="#3185FC",xlab="Sample 1", ylab="Sample 12", main = "Samples (Quantile)")
abline(0,1, col = "red")
```

<div style="text-align: justify">
With the results obtained, we decided to use for the subsequent analysis the <strong>quantile normalization</strong> of the data; in fact, this type of normalization seems more robust and gives better results. If we look at the MvA plots of sample 1 (the reference) VS sample 12, we can see that in the quantile normalization plot the cloud of points is more or less lying on M=0, as it should, while in the TMM normalization plot the cloud of points is clearly hanging below M=0. 
It is to be noted that neither the quantile nor the TMM normalization get rid of the "V-shaped" outliers near low values of A (average). The code below shows what was said here. 
</div>

```{r MvA plot of reference sample (sample 1) VS sample 12 with TMM and quantile normalization, fig.width=12, fig.height=5}
par(mfrow=c(1,3)) 

# Data extraction and plot 
extracted <- samples[,1]
selected  <- samples[,12]

computed  <- MA(extracted, selected)

plot(computed$A, computed$M, pch=20, cex=1,  col="#3185FC",xlab="A", ylab="M", main = "MvA (TMM) ", sub = paste("Sample", 1, "vs.", 12, sep = " "))
abline(0,0, col = "red")

# TMM normalization: data extraction and plot 
extracted <- tmm_normed$samples[,1]
selected  <- tmm_normed$samples[,12]

computed  <- MA(extracted, selected)

plot(computed$A, computed$M, pch=20, cex=1,  col="#3185FC",xlab="A", ylab="M", main = "MvA (TMM) ", sub = paste("Sample", 1, "vs.", 12, sep = " "))
abline(0,0, col = "red")

# Quantile normalization: data extraction and plot 
extracted <- quantile_normed$samples[,1]
selected  <- quantile_normed$samples[,12]

computed  <- MA(extracted, selected)

plot(computed$A, computed$M, pch=20, cex=1,  col="#3185FC",xlab="A", ylab="M", main = "MvA (Quantile)", sub = paste("Sample", 1, "vs.", 12, sep = " "))
abline(0,0, col = "red")
```

## Produce the MvA plots of each sample vs. sample 1 using normalized data to evaluate if the normalization step was correctly performed or if there are outlier samples

<div style="text-align: justify">
You can see MvA plots inside output/plots folder and in particular you can notice that in some of them it's clear what was explained above with reference sample vs. sample 12. For example in reference sample vs. sample 47 plot the same comments can be made: MvA plots clearly show a deviance from M=0 in TMM normalization while this deviance is not present in the analysis with the quantile normalization. This gives credit to the idea that quantile normalization is more robust because it produces a series of sample with the same distribution, while TMM normalization just takes care of the most evident outliers, because it uses a trimmed mean approach.
</div>

```{r Produce Normalized MvA Plots, eval = FALSE}
# TMM Normalization 
produceMvA(tmm_normed$samples, extracted_index, interval,  folder = "MvA - TMM Normalization", graph_title = "MvA (TMM Normalization)")

# Quantile Normalization
produceMvA(quantile_normed$samples, extracted_index, interval,  folder = "MvA - Quantile Normalization", graph_title = "MvA (Quantile Normalization)")

```


<div style="text-align: justify">
As we said in the comment of the chunck above, quantile normalization seems to be more robust because produces a series of sample with the same distribution. This fact it's also evident if you see the following plots, in fact after the application of the TMM normalization, there wasn't any effect on the PCs while using the quantile normalization you can clearly see the change in distribution of both samples and genes and the consequent reduction of the variance inside the data.
</div>

```{r Compute normalized PCA, results='hide', fig.width=7, fig.height=10}
# PCA for samples
tmm_s_pca <- PCA(t(tmm_normed$samples), scale.unit = FALSE, ncp = 10, graph = FALSE)
quantile_s_pca <- PCA(t(quantile_normed$samples), scale.unit = FALSE, ncp = 10, graph = FALSE)

p1 <- fviz_pca_ind(s_pca, col.ind = 'cos2', geom = 'point', title = 'PCA (Samples)')
p2 <- fviz_pca_ind(tmm_s_pca, col.ind = 'cos2', geom = 'point', title = 'PCA (Samples after TMM)')
p3 <- fviz_pca_ind(quantile_s_pca, col.ind = 'cos2', geom = 'point', title = 'PCA (Samples after Quantile)')

grid.arrange(p1,p2, p3)
# PCA for genes
tmm_g_pca <- PCA(tmm_normed$samples, scale.unit = FALSE, ncp = 10, graph = FALSE)
quantile_g_pca <- PCA(quantile_normed$samples, scale.unit = FALSE, ncp = 10, graph = FALSE)


p1 <- fviz_pca_ind(g_pca, col.ind = 'cos2', geom = 'point', title = 'PCA (Genes)')
p2 <- fviz_pca_ind(tmm_g_pca, col.ind = 'cos2', geom = 'point', title = 'PCA (Genes after TMM)')
p3 <- fviz_pca_ind(quantile_g_pca, col.ind = 'cos2', geom = 'point', title = 'PCA (Genes after Quantile)')

grid.arrange(p1, p2, p3)
```

# Second Part

## [Note] There can be the same sample measured twice for a specific subject

<div style="text-align: justify">
We decided to take care of this issue by simply using a mean approach: the samples coming from the same subject and present in the same group (for instance subject 1 is measured two times as a control subject) are mediated. To do this task we decided to implement the remove_duplicates function. 
The function:
<ul>
<li>first of all, we find all subjects duplicated in the group (in our case the group can be "control" or "disease"). To do so, we use the column of the group "individuals"; this column has the identifier for the subjects. If a sample comes from the same subject (i.e, the subject has benn sampled twice or more, so it is a duplicate), the identifier will be the same.</li>
<li>We save all these dupes in a temporary matrix called "duplicate_group"</li>
<li>we initialize a new matrix which will contain all subjects without any of them being duplicated (i.e., sampled twice)</li>
<li>for each identifier in "duplicate_group", we find the indexes of this duplicate individual and get their SRR code (the code with which samples are identified in the matrix of raw data). NB: in the matrix of raw data, all samples are identified with different SRR codes, but SRR codes can point to the same subject.</li>
<li>get all the the samples coming from this particular subject that we know is duplicated</li>
<li>apply the mean by row to all samples identified in the previous step and save this new "mediated-samples subject" in the matrix initialized above</li>
<li>then, find all subjects in the group that are not duplicated (i.e., there's a 1 to 1 correspondance of subject to sample for these individuals)</li>
<li>put all these subjects not duplicated into the matrix initialized above</li>
<li>remove from the matrix any columns not used (we initialized the matrix having the same columns as the group but obviously in the end it will have less columns because some samples will not be present anymore)</li>
end.
</ul>
</div>

```{r remove duplicates function}
remove_duplicates
```

```{r removal of the duplicates}
# get the 'normal' and 'uninvolved mucosa' samples (samples of the control group) 
normal <- LABELS[LABELS$sample_type == c("normal"),]            
unimuc <- LABELS[LABELS$sample_type == c("uninvolved mucosa"),] 

# concatenate and sort samples
control <- rbind(normal, unimuc)                               
control <- control[order(as.numeric(control$individual)),]    

# get the 'colon sessile serrated adenoma/polyp' samples (samples of the disease group)
disease <- LABELS[LABELS$sample_type == c("colon sessile serrated adenoma/polyp"),]

# remove duplicates in the groups
control_nodup <- remove_duplicates(quantile_normed$samples, control)
disease_nodup <- remove_duplicates(quantile_normed$samples, disease) 
```

```{r remove_duplicates outputs}
{# HIDE
# some outputs
cat("The number of control samples is:",nrow(control))
cat("\nThe number of diseased samples is:",nrow(disease))

cat("\nThe number of control samples after duplicates removal is:",ncol(control_nodup))
cat("\nThe number of diseased samples after duplicates removal is:",ncol(disease_nodup))

ratio <- 1-(ncol(control_nodup)/nrow(control))
cat("\nThe compression ratio for control has been of:", ratio)
ratio <- 1-(ncol(disease_nodup)/nrow(disease))
cat("\nThe compression ratio for disease has been of:", ratio)
}# HIDE
```

## [Note] There can be some genes that in both groups 1 and 2 have always expression equal to 0

<div style="text-align: justify">
We took care of the zero problem by taking out genes that had expression always equal to zero in all samples from the control group and the disease group. For instance, say that we look at gene 1: if the sum of the read counts for gene 1 in all the samples coming from control group is zero as it is in all the samples from the disease group then we can say that gene 1 has always expression zero, so it does not give information about differentially expressed genes in disease VS control groups. Gene 1 in this example is therefore taken out. We implemented this in the remove_zeros function.
</div>

```{r remove zero function}
remove_zeros
```

```{r taking care of zeros}
groups_nozero <- remove_zeros(control_nodup, disease_nodup)
control_nodup_nozero<-groups_nozero$control
disease_nodup_nozero<-groups_nozero$disease
```

```{r remove_zeros outputs}
{# HIDE
# some outputs
cat("The number of initial genes is:",nrow(control_nodup))
cat("\nThe number of genes after zeros removal for control is:",nrow(control_nodup_nozero))

ratio <- 1-(nrow(control_nodup_nozero)/nrow(control_nodup))
cat("\nThe compression ratio is:", ratio)
}# HIDE
```

## Calculate p-values of DE analysis (not corrected for multiple testing) between the two groups using t-test, Wilcoxon test and edgeR

<div style="text-align: justify">
For the t-test and the Wilcoxon tests, we use functions of the Stats library.
</div>

```{r p-values}
#initialization of the variables
Nc <- nrow(control_nodup_nozero)
c_ttest_pvalue <- NULL
c_wilcoxon_pvalue <- NULL

# use of the t.test and wilcoxon.test functions for each gene
for(i in (1:Nc)){ 
  c_ttest_pvalue <- c(c_ttest_pvalue,t.test(control_nodup_nozero[i,], disease_nodup_nozero[i,], var.equal = FALSE)$p.value)
  c_wilcoxon_pvalue <- c(c_wilcoxon_pvalue,wilcox.test(control_nodup_nozero[i,],disease_nodup_nozero[i,], exact=FALSE)$p.value)
}
```

<div style="text-align: justify">
For edgeR, we have to do a preprocessing of data and then we use functions of the edgeR library. We have to rebuild the control and disease matrixes with data not normalized because edgeR was created to work with data whose distribution is a negative binomial: the initial data matrix has this type of distribution, while normalized data does not comply to negative binomial distribution. To correctly use the functions we have to label samples in control and disease groups with 'control_1', 'control_2', ..., 'disease_1', and so on. This is done by the utility function rename_columns.
</div>

```{r rename column function}
renameColumns
```

```{r preprocessing}
# rebuilt control matrix and label with the proper name
control_nodup <- remove_duplicates(DATA, control)
control_nodup <- renameColumns(control_nodup, "control")

# rebuilt disease matrix and label with the proper name 
disease_nodup <- remove_duplicates(DATA, disease)
disease_nodup <- renameColumns(disease_nodup, "disease")
```

<div style="text-align: justify">
The next chunk implements edgeR in order to get the pvalues of this test. It is to be noted that the test uses a generalized linear regression approach.
</div>

```{r edgeR}
# merge the two tables of disease and control 
mat <- cbind(disease_nodup, control_nodup)

# create groups and merge them
control_group <- rep("control",dim(control_nodup)[2])
disease_group <- rep("disease",dim(disease_nodup)[2])
group_all <- cbind(t(as.data.frame(disease_group)),t(as.data.frame(control_group)))

# with factor() we get an object divided in two levels (control and disease)
group <- factor(group_all)

# design matrix
design <- model.matrix(~0+group) 
rownames(design) <- colnames(mat)

# fit values of phi (step to fit our GLM model)
y <- DGEList(counts=mat, remove.zeros = TRUE)    
y <- calcNormFactors(y)   # scaling factors with TMM approach
SF <- y$samples

y <- estimateGLMCommonDisp(y,design, verbose=TRUE) # phi common to the entire dataset
y <- estimateGLMTrendedDisp(y,design) # phi depends on mu
y <- estimateGLMTagwiseDisp(y,design) # phi is gene specific
fit <- glmFit(y,design) # the model fit 

# the test
Confr <- makeContrasts(Treatment=groupdisease-groupcontrol,levels=design)
RES <- glmLRT(fit,contrast=Confr[,"Treatment"])

# some outputs to give an idea of the test's results
RES$table[1:5,]

# final values
out <- topTags(RES, n = "Inf")$table
out[1:5,]
```

<div style="text-align: justify">
Boxplots of the p-values obtained by the three tests are shown.
P-values from Wilcoxon test and p-values obtained by edgeR are very similar in their distributions, while the distribution of p-values obtained by t-test differ the most from the other two.
</div>

```{r plot p-values}
boxplot(c_ttest_pvalue, c_wilcoxon_pvalue, out$PValue, names = c('t-test','Wilcoxon test', 'edgeR'), main = 'p-values')
```

## Calculate the expected number of false positives (FP) and false negatives (FN) in correspondence to the choice of alpha = 0.05 and consider G0 = N with N being the number of genes

<div style="text-align: justify">
For each test, we extracted the genes that have p-value lower than a fixed alpha. These are the selcted genes.
With the following function "expected_values" we calculate the expected values of true positives, false positives, true negatives and false negatives implementing their definition. In order of calculation:
<ul>
<li>False positives are calculated as the minimum between G0*alpha and the number of selected genes,</li>
<li>True positives are calculated as the maximum between zero and the number of selected genes minus the number of expected positives,</li>
<li>True negatives as G0 minus the number of expected false positives,</li>
<li>and lastly, False negatives as the maximum between zero and the total number of genes minus the selected ones and minus the number of expected true negatives; in this case, the maximum is applied as not to have deviant values for FN, meaning negative values.</li>
</ul>
We then applied the function considering G0 (number of selected genes) being equal to G, the total number of genes.
</div>

```{r selection for alpha 0.05}
alpha<-0.05

# selected values for t-test
lower <- (c_ttest_pvalue<alpha)
selected_ttest <- which(lower==TRUE)
num_sel_ttest <- length(selected_ttest)

# selected values for Wilcoxon test
lower <- (c_wilcoxon_pvalue<alpha)
selected_wilcox <- which(lower==TRUE)
num_sel_wilcox <- length(selected_wilcox)

#selected values for edgeR
num_sel_edgeR <- length(which(out$PValue<alpha)) #i selected

{# HIDE
cat("Results")
cat("\nNumber of selected genes with t-test:",num_sel_ttest)
cat("\nNumber of selected genes with Wilcoxon-test:",num_sel_wilcox)
cat("\nNumber of selected genes with edgeR:",num_sel_edgeR)
}# HIDE
```

```{r expected values function}
expected_values
```

```{r calculation of expected values}
G <- nrow(control_nodup_nozero)
G0 <- G

#function that returns a vector with, in order, TP FP TN FN
expected_ttest <- expected_values(G, G0, alpha, num_sel_ttest)
expected_wilcoxontest <- expected_values(G, G0, alpha, num_sel_wilcox)
expected_edger <- expected_values(G, G0, alpha, num_sel_edgeR)

dt <- rbind(expected_ttest,expected_wilcoxontest,expected_edger)
dt <- cbind(c(G0,G0,G0),dt)
rownames(dt)<-c('t-test', 'Wilcoxon-test', 'edgeR')
colnames(dt)<-c('G0 = G','TP', 'FP', 'TN', 'FN')
dt %>% kbl() %>% kable_paper("hover", full_width = T)
```

## Estimate the number of not differentially expressed genes G0 and re-estimate the expected number of false positives and false negatives

<div style="text-align: justify">
The first function calculates the values of G0 for a given set of lambda values. It's used to estimate the correct value of G0 rather than assuming that G0 is equal to the total number of genes. It receives in input also the p-values for which the computation must be done, the total number of genes G and the filename in which the plot of "G0 VS lambda" should be saved. From the plot of G0/G VS lambda we choose by hand the best value for our lambda (for instance, in the case of edgeR, 0.65) and with the second function, we provide an estimate of G0 with the previous lambda value passed as input (considering a mean of the values of G0 within an interval around the best lambda; the interval is chosen by epsilon).  
</div>

```{r G0 values function}
G0values
```

```{r estimation of G0 function}
G0_value_estimation
```

<div style="text-align: justify">
In the following chunk we perform the estimation of G0 with the functions described above; after seeing the plots, we choose our lambdas in the three cases (the three tests); those lambdas were chosen because we saw that around them the respective graphs had a constant mean value with little variability.
</div>

``` {r estimation of G0 and re-estimation of the values for each test}
lambda<-seq(0, 0.99, 0.01)

# t-test analysis
res <- G0values(lambda,c_ttest_pvalue, G0, "T test")
lambda_est_ttest <- 0.8
eps <- 0.03
G0_est_ttest <- G0_value_estimation(lambda_est_ttest, eps, res)

expected_ttest_est <- expected_values(G, G0_est_ttest, alpha, num_sel_ttest)

# Wilcoxon analysis
res <- G0values(lambda,c_wilcoxon_pvalue, G0, "Wilcoxon test")
lambda_est_wilcoxon <- 0.8
eps <- 0.03
G0_est_wilcoxontest <- G0_value_estimation(lambda_est_wilcoxon, eps, res)

expected_wilcoxontest_est <- expected_values(G, G0_est_wilcoxontest, alpha, num_sel_wilcox)

# edgeR analysis
res <- G0values(lambda,out[,4], G0, "edgeR test")
lambda_est_edger <- 0.65
eps <- 0.03
G0_est_edger <- G0_value_estimation(lambda_est_edger, eps, res)

expected_edgeR_est <- expected_values(G, G0_est_edger, alpha, num_sel_edgeR)
```

<div style="text-align: justify">
In the table below, we provide the results of the three tests in terms of FP, FN, TP, TN rates; moreover, we address sensitivity, specificity and accuracy of these tests. For better understanding, this ananlysis is done ultimately only for the results obtained by estimating G0.
From the table we can see that although having slightly different FP, FN, TP, TN rates, the three tests have the same specificity, defined as TN/(TN+FP). This is not true for sensitivity: edgeR is the best test in terms of sensitivity defined as TP/(TP+FN). The same can be said about accuracy, calculated as (TP+TN)/(TP+TN+FP+FN); edgeR is still the best performing test.
</div>

```{r sensitivity, specificity, accuracy}
sensitivity <- c((expected_ttest_est$TP/(expected_ttest_est$TP+expected_ttest_est$FN)),
                 (expected_wilcoxontest_est$TP/(expected_wilcoxontest_est$TP+expected_wilcoxontest_est$FN)),
                 (expected_edgeR_est$TP/(expected_edgeR_est$TP+expected_edgeR_est$FN)))

specificity <- c((expected_ttest_est$TN/(expected_ttest_est$TN+expected_ttest_est$FP)),
                 (expected_wilcoxontest_est$TN/(expected_wilcoxontest_est$TN+expected_wilcoxontest_est$FP)),
                 (expected_edgeR_est$TN/(expected_edgeR_est$TN+expected_edgeR_est$FP)))

accuracy <- c(((expected_ttest_est$TN+expected_ttest_est$TP)/(expected_ttest_est$TP+expected_ttest_est$TN+expected_ttest_est$FP+expected_ttest_est$FN)),
              ((expected_wilcoxontest_est$TN+expected_wilcoxontest_est$TP)/(expected_wilcoxontest_est$TP+expected_wilcoxontest_est$TN+expected_wilcoxontest_est$FP+expected_wilcoxontest_est$FN)),
              ((expected_edgeR_est$TN+expected_edgeR_est$TP)/(expected_edgeR_est$TP+expected_edgeR_est$TN+expected_edgeR_est$FP+expected_edgeR_est$FN)))
```

```{r results, echo=FALSE}
dt <- rbind(expected_ttest_est,expected_wilcoxontest_est,expected_edgeR_est)
dt <- cbind(c(G0_est_ttest,G0_est_wilcoxontest,G0_est_edger),dt,sensitivity,specificity,accuracy)
rownames(dt)<-c('t-test', 'Wilcoxon-test', 'edgeR')
colnames(dt)<-c('G0 estimated','TP', 'FP', 'TN', 'FN','Sensitivity','Specificity', 'Accuracy')
kbl(dt) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

## Choose the “best” test among t-test, Wilcoxon test and edgeR motivating your choice

<div style="text-align: justify">
We chose edgeR for few reasons; first of all, edgeR implements a test for data with negative binomial distribution, while the other tests do not take into account the characteristics of this particular distribution and, in this sense, this analysis can give more specific results. Then, it must also be said that it gives the lowest FN rate; while FP rate can be easily taken into account with a correction for multiple tests, FN rate is not accounted for with this type of correction. In this sense, we are not able to reduce this rate with some corrections; since ideally one should want a FN and FP rates equal to zero, we have to minimize them. Finally, edgeR performs better than the other two tests in terms of both sensitivity and accuracy. 
To conclude, we chose edgeR on the basis of the theory behind it and also on the calculated FP and FN rates, sensitivity and accuracy.
</div>

## Select the final list of DE genes using the test chosen at point 4 and a false discovery rate threshold of 5%

<div style="text-align: justify">
The next chunk performs the FDR estimation to correct for multiple testing.
First of all, we compute the lambda values choosing an interval within the minimum and maximum values of edgeR's p-values;for each of them we compute FDR value by definition as the expected number of false positives divided by the number of selected for said value of lambda. Then, we estimate the alpha value as the mean of alphas which have FDR close to 0.05 by a certain epsilon (0.0001).
</div>

```{r choose alpha}
FDR <- 0.05
# values in the range observed as p-value in edgeR
lambda <- seq(min(out[,4]), max(out[,4]), (max(out[,4])-min(out[,4]))/nrow(out))
FDR_values <- NULL

# compute FDR for every lambda
for (i in (1:length(lambda))) {
  less <- (out[,4]<lambda[i])
  num_sel <- length(which(less==TRUE))
  
  expected_val <- expected_values(G, G0_est_edger, lambda[i], num_sel)
  
  if (num_sel==0) FDR_values <- c(FDR_values, 0)
  else FDR_values <- c(FDR_values, (expected_val$FP/num_sel))
  
}

plot(lambda, FDR_values, main = 'FDR values for different alpha', xlab="alpha", ylab= "FDR")

# choose the values that are in [0.05-epsilon;0.05 + espilon]
epsilon <- 0.0001
alpha_idx_lower <- which(FDR_values >= FDR - epsilon)
alpha_idx_upper <- which(FDR_values <= FDR + epsilon)
alpha_est <- mean(lambda[intersect(alpha_idx_lower, alpha_idx_upper)])
```

<div style="text-align: justify">
We finally select the genes with p-value given by edgeR lower than the estimated alpha.
</div>

```{r extraction}
# selection of the correspondent indexes and ID genes in the table
indexes <- which(out$PValue<alpha_est) 
index_genes_selected <- sort(as.numeric(rownames(out[indexes,])))

ID_genes_selected <- rownames(DATA[index_genes_selected,])
number_genes_selected <- length(ID_genes_selected)
ID_genes_notselected <- setdiff(rownames(DATA),ID_genes_selected)
number_genes_notselected <- length(ID_genes_notselected)

{# HIDE
# print results
cat("Number of selected genes: ", number_genes_selected, "\n")
cat("Number of not selected genes: ", number_genes_notselected)
}# HIDE

```

# Third Part

## Extract G0 term associated

<div style="text-align: justify">
We found out that some gene names were duplicated but not their ENSEMBL IDs; for this reason, we decided to use these IDs to get the annotation and extract the right GO terms associated with the genes. We also decided to take out those genes whose GOALL was NA: as a matter of fact, this NA value means that we don't have their associated term right now (the association is not complete in the DB).  To improve computation, we also took out all the IDs of genes annotated but not selected and their respective total numbers. 
After the data extraction and the pre-processing, we built a matrix that has on rows the associated GO terms and on columns the type of GOterm (BP, CC, MF) and the values useful for the computation of the fisher test.
</div>

```{r extract GO terms}
# extraction of the associated terms in function of the ENSEMBL ID 
alldata <- select(org.Hs.eg.db, ID_genes_selected, columns = c("SYMBOL","ENTREZID", "ENSEMBL","GOALL"), keytype="ENSEMBL")

# remove the genes for which we have the NA term associated 
GOALL_NA <- which(is.na(alldata$GOALL))
ID_goall_na <- alldata$ENSEMBL[GOALL_NA]

ID_genes_selected_notna <- setdiff(ID_genes_selected,ID_goall_na)
number_genes_selected_notna <- length(ID_genes_selected_notna)
ID_genes_notselected_notna <- setdiff(ID_genes_notselected,ID_goall_na)
number_genes_notselected_notna <- length(ID_genes_notselected_notna)

# remove the duplicates in the extracted terms 
terms <- unique(alldata[,4])
terms <- terms[!is.na(terms)]

{# HIDE
# print outputs
cat("Number of unique extracted terms: ", length(terms), "\n")
cat("Number of selected genes not NA: ", number_genes_selected_notna)
}# HIDE

#creation of the matrix for the Fisher test, one row for each GOterm
matrixes <- NULL
for (i in (1:length(terms))){
  GOterm <- terms[i]
  GOterm_indexes <- which(alldata$GOALL==GOterm)
  a <- length(intersect(alldata[GOterm_indexes,1],ID_genes_selected_notna))
  b <- number_genes_selected - a
  c <- length(GOterm_indexes) - a
  d <- length(ID_genes_notselected_notna)- c
  type<-alldata[(which(alldata[,4]==GOterm))[1],6]

  matrixes <- rbind(matrixes,c(type,a,b,c,d))
}

colnames(matrixes)<-c("type","a","b","c","d")
rownames(matrixes)<-terms
matrixes<-matrixes[order(rownames(matrixes)),]
```

## Fisher test

<div style="text-align: justify">
These functions were implemented to perform the fisher exact test.
"fisher_test_matrixes" computes the actual test, returning the p-values of each test.
"FDR_fisher" calculates the estimated alpha given a FDR equal to 0.05 in order to account for multiple testing in the selection of meaningful p-values (and subsequently meaningful annotations).
"annotation_terms" return the annotated terms for the GOterms selected as meaningful; to do so it uses the GO.db databases. 
</div>

```{r fisher functions}
fisher_test_matrixes
FDR_fisher
annotation_terms
```

```{r fisher test}
# creation of three sub-matrices in function of the GOterm's type  
matrixesCC <- matrixes[which(matrixes[,1]=="CC"),]
indexCC<-which(matrixes[,1]=="CC")
terms_CC<-terms[indexCC]
colnames(matrixesCC)<-c("type","a","b","c","d")
matrixesBP <- matrixes[which(matrixes[,1]=="BP"),]
indexBP<-which(matrixes[,1]=="BP")
terms_BP<-terms[indexBP]
colnames(matrixesBP)<-c("type","a","b","c","d")
matrixesMF <- matrixes[which(matrixes[,1]=="MF"),]
indexMF<-which(matrixes[,1]=="MF")
terms_MF<-terms[indexMF]
colnames(matrixesMF)<-c("type","a","b","c","d")

pval_fisherCC<-fisher_test_matrixes(matrixesCC)
pval_fisherBP<-fisher_test_matrixes(matrixesBP)
pval_fisherMF<-fisher_test_matrixes(matrixesMF)

# correction for multiple testing in fisher

fisher_analysis_BP<-FDR_fisher(pval_fisherBP,terms_BP)
number_terms_annotatedBP<-length(fisher_analysis_BP[[1]])

fisher_analysis_CC<-FDR_fisher(pval_fisherCC,terms_CC)
number_terms_annotatedCC<-length(fisher_analysis_CC[[1]])

fisher_analysis_MF<-FDR_fisher(pval_fisherMF,terms_MF)
number_terms_annotatedMF<-length(fisher_analysis_MF[[1]])

# ATTENIONE: NON BISOGNA AVERE DPLYR IN LIBRERIA! (SOVRASCRIVE SELECT)
vals = select(GO.db, keys(GO.db, "GOID"), c("TERM", "ONTOLOGY"))

annotation_terms_BP<-as.data.frame(annotation_terms(vals, fisher_analysis_BP[[2]]))
colnames(annotation_terms_BP)<-"terms"
annotation_terms_CC<-as.data.frame(annotation_terms(vals, fisher_analysis_CC[[2]]))
colnames(annotation_terms_CC)<-"terms"
annotation_terms_MF<-as.data.frame(annotation_terms(vals, fisher_analysis_MF[[2]]))
colnames(annotation_terms_MF)<-"terms"
```

<div style="text-align: justify">
Just some outputs of the annotation process; these annotated terms are some of the terms linked to tumor growth.
</div>

```{r extract_tumor_terms function}
extract_tumor_terms
```

```{r annotation outputs}
to_viewBP<-extract_tumor_terms(annotation_terms_BP)
to_viewCC<-extract_tumor_terms(annotation_terms_CC)
to_viewMF<-extract_tumor_terms(annotation_terms_MF)
minimum<-min(length(to_viewBP), length(to_viewCC), length(to_viewMF))

dt <- cbind(to_viewBP[1:minimum],to_viewMF[1:minimum], to_viewCC[1:minimum] )
#rownames(dt)<-c('BP', 'MF', 'CC')
colnames(dt)<-c('BP','MF', 'CC')
kbl(dt) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```


```{r fisher - most important terms (by lowest pval)}
#most important == lowest pval

pval_fisherCC_sorted<-sort(fisher_test_matrixes(matrixesCC))
pval_fisherBP_sorted<-sort(fisher_test_matrixes(matrixesBP))
pval_fisherMF_sorted<-sort(fisher_test_matrixes(matrixesMF))

# correction for multiple testing in fisher 

fisher_analysis_BP_sorted<-FDR_fisher(pval_fisherBP_sorted,terms_BP)
fisher_analysis_CC_sorted<-FDR_fisher(pval_fisherCC_sorted,terms_CC)
fisher_analysis_MF_sorted<-FDR_fisher(pval_fisherMF_sorted,terms_MF)


annotation_terms_BP_sorted<-as.data.frame(annotation_terms(vals, fisher_analysis_BP_sorted[[2]]))
colnames(annotation_terms_BP_sorted)<-"terms"
annotation_terms_CC_sorted<-as.data.frame(annotation_terms(vals, fisher_analysis_CC_sorted[[2]]))
colnames(annotation_terms_CC_sorted)<-"terms"
annotation_terms_MF_sorted<-as.data.frame(annotation_terms(vals, fisher_analysis_MF_sorted[[2]]))
colnames(annotation_terms_MF_sorted)<-"terms"

#the most important annotated terms are at the end of the list - we show the 10 more important ones
tot_BP<-dim(annotation_terms_BP_sorted)[1]
to_viewBP_sorted<-annotation_terms_BP_sorted[(tot_BP-10):tot_BP,]
tot_CC<-dim(annotation_terms_CC_sorted)[1]
to_viewCC_sorted<-annotation_terms_CC_sorted[(tot_CC-10):tot_CC,]
tot_MF<-dim(annotation_terms_MF_sorted)[1]
to_viewMF_sorted<-annotation_terms_MF_sorted[(tot_MF-10):tot_MF,]

dt <- cbind(to_viewBP_sorted,to_viewMF_sorted, to_viewCC_sorted )
#rownames(dt)<-c('BP', 'MF', 'CC')
colnames(dt)<-c('BP','MF', 'CC')
kbl(dt) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

# Fourth Part 

## [Note] Correcting for length of genes before clustering

<div style="text-align: justify">
We correct our data for the length of genes to perform a better clustering analysis and to not have a bias in the results do to the lengths. To do it we extracted the gene lengths with the 'getGeneLengthAndGCContent' function and then divide each value for its length. We also decided to consider as one sample all those samples taken from the same subject in the same group, as we did for testing the DE genes.
</div>

```{r init clustering, results='hide'}
d <- getGeneLengthAndGCContent(ID_genes_selected, "hsa")
#d[[1]] has the length of all genes selected

# remove the first column of data (gene names), extract the selected genes and normalize them
data_normalized <- samples
data_normalized <- data_normalized[index_genes_selected,]
data_normalized <- t(t(data_normalized)/d[[1]])

# remove the duplicates and bind them
dataNorm_nodup_control <- remove_duplicates(data_normalized,control) 
dataNorm_nodup_disease <- remove_duplicates(data_normalized,disease) 
dataNorm_clustering <- cbind(dataNorm_nodup_control,dataNorm_nodup_disease)
```

## Cluster the genes you have selected in exercise 2 using k-means and hierarchical clustering and compare the results you obtain

<div style="text-align: justify">
We defined a grid of possible values for the number of clusters and for each of them we implement the clustering, with the kmeans function of R. For THIS function, we used as parameters iter.max=100 to avoid a too long computation or an overfitting of the data and nstart=100 to have multiple startings that lead to better results trying to avoid local minimum of the cost function. 
For the hierarchical cluster, we used the hclust function of R, with as parameter method="ward.D2": we chose ward.D2 as a method of clustering because it uses the euclidean distance and in this way we can perform a better comparison with k-means, which also uses euclidean distance. Once the entire hierarchical tree is build, we cut the tree in order to obtain different numbers of clusters (inside the for cycle).
In each iteration on possible values of k = number of clusters, we calculate also the Silhouette value.
</div>

```{r values of K}
K <- seq(1,10)
```

```{r clustering genes with kmeans}
# Clustering genes with kmeans

WITHIN_SS_gene_kmeans <- NULL
clus_km <- NULL
s_genes_kmeans <- NULL

for(i in K){
  k <- K[i]
  cl_kmeans_genes <- kmeans(x=dataNorm_clustering,centers=k,iter.max=100,nstart=3)
  clus_km <- c(clus_km,cl_kmeans_genes)
  WITHIN_SS_gene_kmeans <- rbind(WITHIN_SS_gene_kmeans, cl_kmeans_genes$tot.withinss)
  s_genes_kmeans <- rbind(s_genes_kmeans, silhouette(dataNorm_clustering,cl_kmeans_genes[[1]], k))
}
```

```{r clustering genes with hierarchical}
# Clustering genes with hierarchical

D <- dist(dataNorm_clustering) 
cl_hclust_ward <- hclust(d=D, method="ward.D2")

s_genes_hierar <- NULL

for (i in (1:length(K))){
  k <- K[i]
  clusters_hclust_ward <- cutree(cl_hclust_ward, k=k)
  s_genes_hierar <- c(s_genes_hierar, silhouette(dataNorm_clustering,clusters_hclust_ward,k))
}
```

## Cluster the samples in your dataset (considering only the genes you have selected in exercise 2) using k-means and hierarchical clustering and compare the results you obtain

<div style="text-align: justify">
All the implementation and the parameters are equal to the implementation above. We only had to consider the transpose of the initial data matrix to cluster the samples instead of the genes.
</div>

```{r clustering sample with kmeans}
# Clustering samples with kmeans

WITHIN_SS_sample <- NULL
clus_km_sample <- NULL
s_samples_kmeans <- NULL

for(i in K) {
  k<-K[i]
  cl_kmeans_samples<-kmeans(x=t(dataNorm_clustering),centers=k,iter.max=100,nstart=100)
  clus_km_sample<-c(clus_km_sample,cl_kmeans_samples)
  WITHIN_SS_sample<-rbind(WITHIN_SS_sample, cl_kmeans_samples$tot.withinss)
  s_samples_kmeans <- rbind(s_samples_kmeans, silhouette(t(dataNorm_clustering),cl_kmeans_samples[[1]], k))
}
```

```{r clustering sample with hierarchical}
# Clustering samples with hierarchical

D<-dist(t(dataNorm_clustering)) 
cl_hclust_ward_S<-hclust(d=D,method="ward.D2")

s_samples_hierar <- NULL

for (i in (1:length(K))){
  k <- K[i]
  clusters_hclust_ward_S<-cutree(cl_hclust_ward_S, k=k)
  s_samples_hierar <- c(s_samples_hierar, silhouette(t(dataNorm_clustering),clusters_hclust_ward_S,k))
}
```

## Choose the optimal number of clusters using the silhouette statistic

```{r silhouette implementation}
silhouette
```

```{r results of the sihouette}
# results for silhouette
{# HIDE
cat("K-Means over genes!\n")
kopt_g_kmeans_sil <- K[which(s_genes_kmeans == max(s_genes_kmeans))]
cat("The maximum silhouette is", s_genes_kmeans[kopt_g_kmeans_sil], ", obtained for the optimal number of clusters:", kopt_g_kmeans_sil)

cat("\n\nHierarchical clustering over genes!\n")
kopt_g_hier_sil <- K[which(s_genes_hierar == max(s_genes_hierar))]
cat("The maximum silhouette is", s_genes_hierar[kopt_g_hier_sil], ", obtained for the optimal number of clusters:", kopt_g_hier_sil)

cat("\n\nK-Means over samples!\n")
kopt_s_kmeans_sil <- K[which(s_samples_kmeans == max(s_samples_kmeans))]
cat("The maximum silhouette is", s_samples_kmeans[kopt_s_kmeans_sil], ", obtained for the optimal number of clusters:", kopt_s_kmeans_sil)

cat("\n\nHierarchical clustering over samples!\n")
kopt_s_hier_sil <- K[which(s_samples_hierar == max(s_samples_hierar))]
cat("The maximum silhouette is", s_samples_hierar[kopt_s_hier_sil], ", obtained for the optimal number of clusters:", kopt_s_hier_sil)
}# HIDE
```

## Choose the optimal number of clusters using the Gap statistic. In this case you can use the R function clusGap() in the library “cluster”

<div style="text-align: justify">
To implement the gap statistic, we used the clusGap function of the cluster library. For each analysis we implemented before, we determined the best number of clusters with its definition. 
</div>

```{r gap, fig.width=7, fig.height=7}
# results for the gap statistic
#functions for the subsequent analysis
test_hclust <- function(x, k) list(cluster=cutree(hclust(dist(x), method = "average"),k=k))
test_kmeans <- function(x, k) (kmeans(x=x, centers=k, iter.max=100, nstart=100))

# K-Means - genes

gap_res<-clusGap(dataNorm_clustering, test_kmeans, length(K), B=20)

for (i in (2:(nrow(gap_res$Tab)-1))){
  if ((gap_res$Tab[i,3])>(gap_res$Tab[i+1,3]+gap_res$Tab[i+1,4]))
    break;
}
kopt_g_kmeans_gap <- i

# K-Means - samples

gap_res<-clusGap(t(dataNorm_clustering), test_kmeans, length(K), B=20)

for (i in (2:(nrow(gap_res$Tab)-1))){
  if ((gap_res$Tab[i,3])>(gap_res$Tab[i+1,3]+gap_res$Tab[i+1,4]))
    break;
}
kopt_s_kmeans_gap <- i

# Hierarchical - genes

gap_res<-clusGap(dataNorm_clustering, test_hclust, length(K), B=20)

for (i in (2:(nrow(gap_res$Tab)-1))){
  if ((gap_res$Tab[i,3])>(gap_res$Tab[i+1,3]+gap_res$Tab[i+1,4]))
    break;
}
kopt_g_hier_gap <- i

# Hierarchical - samples

gap_res <-clusGap(t(dataNorm_clustering), test_hclust, length(K), B=20)

for (i in (2:(nrow(gap_res$Tab)-1))){
  if ((gap_res$Tab[i,3])>(gap_res$Tab[i+1,3]+gap_res$Tab[i+1,4]))
    break;
}
kopt_s_hier_gap <- i
```

```{r results of the gap statistic}
{# HIDE
# results for gap statistic
cat("K-Means over genes!\n")
cat("The optimal number of clusters is:", kopt_g_kmeans_gap)

cat("\n\nHierarchical clustering over genes!\n")
cat("The optimal number of clusters is:", kopt_s_kmeans_gap)

cat("\n\nK-Means over samples!\n")
cat("The optimal number of clusters is:", kopt_g_hier_gap)

cat("\n\nHierarchical clustering over samples!\n")
cat("The optimal number of clusters is:", kopt_s_hier_gap)
}# HIDE
```

<div style="text-align: justify">
Plots of the clusterings are shown, for both kmeans and hieararchical clustering. 
</div>

```{r plots of part4, HIERARCHICAL}
#GENES, HIERARCHICAL CLUSTERING
hcd_G <- as.dendrogram(cl_hclust_ward)
fviz_dend(cut(hcd_G, h=400)$lower[[1]], k = kopt_g_hier_gap, cex = 0.5, k_colors = c("#2E9FDF",  "#FC4E07"),
             color_labels_by_k = T, rect = F, show_labels = T, horiz = T, main="Hierarchical (Genes) - Upper")  
fviz_dend(cut(hcd_G, h=400)$lower[[2]], k = kopt_g_hier_gap , cex = 0.5, k_colors = c("#2E9FDF",  "#FC4E07"),
             color_labels_by_k = T, rect = T, show_labels = F, horiz = T, main="Hierarchical (Genes) - Lower")  

# SAMPLES, HIERARCHICAL CLUSTERING
hcd_S <- as.dendrogram(cl_hclust_ward_S)
fviz_dend(hcd_S, k = kopt_s_hier_gap, cex = 0.5, k_colors = c( "#E7B800",  "#00AFBB"), 
          color_labels_by_k = T, rect = T, rect_fill = T, show_labels = T, main="Hierarchical (Samples) - Upper")
```

```{r plot of part 4, kmeans, fig.width=7, fig.height=7}
#GENES, KMEANS
cl_genes<-kmeans(x=dataNorm_clustering, centers = kopt_g_kmeans_gap, iter.max = 100, nstart = 100)
p1<-fviz_cluster(cl_genes, data = dataNorm_clustering,
             palette = c("#2E9FDF", "#00AFBB"), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw(),
             main="K-means (Genes)"
)

#SUBJECTS, KMEANS
dataNorm_clustering_plot<-dataNorm_clustering
colnames(dataNorm_clustering_plot)<-NULL
cl_samples<-kmeans(x=t(dataNorm_clustering_plot), centers = kopt_s_kmeans_gap, iter.max = 100, nstart = 100)
p2<-fviz_cluster(cl_samples, data = t(dataNorm_clustering_plot),
             palette = c("#2E9FDF", "#00AFBB", "#E7B800"), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw(),
             main="K-means (Subjects)"
)

grid.arrange(p1, p2, nrow = 2)
```

# Fifth Part

## Considering the two groups you have used for differential expression analysis split your data in training and test

<div style="text-align: justify">
To build the dataset for the SVM analysis, we considered the selected genes and the two groups (control and disease seen above) and we did some pre-processing: first of all, duplicates in samples are removed with the function implemented and explained above. We then removed also the genes for which the expression values are always zero in both the groups. This will determine the data to use for SVM classification, divided then into training and test set randomly, saving the labels needed for the classification (the belonging to the control or to the disease group of each sample). 
For the subsequent implementation, we had to remove also the genes for which the expression is zero in all samples in control or all samples in disease. When taking away said genes, they must be taken away also in the other set. They won't be of any use in the classification process; in fact, in the pre-processing of data, mean and standard deviations must be computed to be used for z-scoring said data; if a gene has always expression zero in all samples, its standard deviation will also be zero. Dividing by zero is not possible, so NA will be inserted in that column; the training will then be stopped because NA will be found. For this reason, we implemented a function to remove those genes, in a very similar fashion to the function for removing zeros explained above.
</div>

```{r function remove_zeros_onegroup}
remove_zeros_onegroup 
```

```{r data splitting}
set.seed(1000)

# extract data, remove duplicates and zeros
data_nodup_control <- remove_duplicates(samples[index_genes_selected,], control) 
data_nodup_disease <- remove_duplicates(samples[index_genes_selected,], disease)
groups_nozero <- remove_zeros(data_nodup_control, data_nodup_disease)
data_nodup_control <- groups_nozero$control
data_nodup_disease <- groups_nozero$disease
data_SVM <- cbind(data_nodup_control, data_nodup_disease)
# assign its ID to each gene
rownames(data_SVM) <- ID_genes_selected[-(groups_nozero$removedindexes)]
# construct the vector for control and disease 
namegroup <- c(rep("control", ncol(data_nodup_control)),rep("disease", ncol(data_nodup_disease)))

# separate in train and test, both data and labels
trainIndex <- createDataPartition((1:ncol(data_SVM)), p=0.7, list=FALSE, times=1)
data_train <- data_SVM[,trainIndex]
data_test <- data_SVM[,-trainIndex]

label_train <- namegroup[trainIndex]
label_test <- namegroup[-trainIndex]

# we can still have genes in data_train and data_test for which all values are 0: we remove these genes (if in one group it generates this problem, we have to remove that gene also from the other group).
train_removed <- remove_zeros_onegroup(data_train)
data_train <- train_removed$group
data_test <- data_test[-train_removed$removedindexes,]

# finally, take the transpose to have samples on the rows
data_test<-t(data_test)
data_train<-t(data_train)
```

```{r final sets}
{# HIDE
cat("The training set contains",nrow(data_train),"samples, each one with",ncol(data_train),"genes. It contains",length(which(label_train=="control")),"samples of the control group and", length(which(label_train=="disease")), "samples of the disease group.")
cat("\nThe test set contains",nrow(data_test),"samples, each one with",ncol(data_test),"genes. It contains",length(which(label_test=="control")),"samples of the control group and", length(which(label_test=="disease")), "samples of the disease group.")
}# HIDE
```

## Standardize each feature in your dataset 

<div style="text-align: justify">
The dataset contains all data of the control and disease groups only for the genes selected with the differential expression analysis. To standardize each features in the dataset (so to have mean=0 and sd=1), we used the scale function. Z-scoring is implemented: to z-score the data set, mean and standard deviation of the training set is used. We can perform the standardization of both of sets with the values of the training set. This is done because in the reality, when a single new vector from a subject needs to be classified, it is not possible to use its mean and standard deviation (for each gene, we would have only one value) and it is so scaled with the already known information. 
In the second part, we add at the top of the dataframes containing the training set and the test set the label of each sample, inserting them as a factor variable.
</div>

```{r data preprocessing}
dataNorm_train <- scale(data_train)

mean_train <- apply(data_train,2,mean)
sd_train <- apply(data_train,2,sd)
dataNorm_test <- scale(data_test, center = mean_train, scale = sd_train)

# create data.frames in which in the first element we have the factor element
dataNorm_train<-as.data.frame(dataNorm_train)
dataNorm_train<-cbind('Group'=factor(label_train),dataNorm_train)

dataNorm_test<-as.data.frame(dataNorm_test)
dataNorm_test<-cbind('Group'=factor(label_test),dataNorm_test)
```

## Use linear support vector machines to learn classifying your subjects in the two classes 

<div style="text-align: justify">
We implemented the SVM procedure with both Caret and e1071 packages and we printed some results. We can see that the results for the two methods are equal. With caret, we set the model to predict the Group variable in the normalized dataset with a linear SVM, without performing any scaling (it has been already performed) and trying to maximize the accuracy of the model thanks to a repeated cross validation procedure. With e1071, we set at most the same parameters to fit a linear model for classification.
</div>

```{r caret}
# train the model
model <- train(Group~., data=dataNorm_train, method = "svmLinear", scale = FALSE, na.action=na.fail, metric = "Accuracy", maximize = TRUE, trControl = trainControl(method = "repeatedcv", number =10, repeats = 3))
summary(model)

# only some stupid results
cat("Prediction for the training set:\n")
train_pred <- predict(model,dataNorm_train)
confusionMatrix(train_pred, factor(label_train))

# test the model on the test set
cat("Prediction for the test set:\n")
test_pred <- predict(model,dataNorm_test)
confusionMatrix(test_pred, factor(label_test))
```

```{r e1071}
svmfit <- svm(Group~., data = dataNorm_train, kernel = "linear", type = 'C-classification', scale = FALSE, cross = 10)
print(svmfit)
{# HIDE
cat("Prediction for the test set:\n")
test_pred <- predict(svmfit, newdata=dataNorm_test, decision.values = FALSE)
res <- confusionMatrix(test_pred, factor(label_test))
print(res)
}# HIDE
```

## Feature selection

<div style="text-align: justify">
A recursive feature elimination algorithm is implemented in the function below. First of all, the SVM model is built for the entire dataset passed in input using a c-fold cross validation (with c in input, or by default c = 5 - it will be used also in all the SVM computations inside the function). Then, recursively, a certain percentage (at the beginning of 15%) of features are removed: in the first while cycle, are removed the features with lower weight in the previous model. The model according to the new dataset is built and if we obtain a worst result in terms of accuracy, the current iteration is aborted and restarting from the previous model and dataset, a lower percentage of features is removed. If the model is instead with the same or greater accuracy, it is saved as the best model found until that iteration (because of the less number of features needed and the higher accuracy). This cycle continues until one single feature should be removed, until it remains with less then K (passed in input, 500 by default) or until a too low accuracy (0.9*the initial one) is obtained. In the subsequent while cycle, one feature at iteration is removed: it chooses the one that less affects the model accuracy. The whole cycle continues until a single feature remains. 
The function returns the numbers of features used in each iteration and the correspondent accuracy, the best model (higher accuracy and lower number of features) with the correspondent accuracy and genes ID used. It returns also all the model obtained in the second while cycle (with corresponding genes ID).
</div>

```{r implemented rfe function CV}
recursiveFeatureExtractionCV
```

```{r funCV}
rfe <- recursiveFeatureExtractionCV(dataNorm_train, label_train, 500, 10)
#plot (x = rfe$number_features, y = rfe$accuracy, xlab = "Features retained", ylab = "Accuracy")
```

<div style="text-align: justify">
With the best model returned by recursiveFeatureExtractionCV, we now evaluate its performances with the test set. In the first chunk, the best model is evaluated in terms of prediction on the test set (and a check on its performances on the entire training set). In the second chunk, the SVM and the training set are plotted in terms of the two best features (the two with highest weight in the model). 
</div>

```{r tests of rfe}
best_genes <- (rfe$bestmodel)$names
best_model <- (rfe$bestmodel)$svm
matrix_train <- dataNorm_train[,best_genes]
matrix_train <- cbind('Group'=factor(label_train),matrix_train)

# Performances on the test set 
pred_prova <- predict(best_model, newdata=dataNorm_test, decision.values = FALSE)
res_prova <- confusionMatrix(pred_prova, factor(label_test))  
print(res_prova)

# Check the performances
svmfit_prova <- svm(Group ~ ., data = matrix_train, kernel = "linear", type = 'C-classification', scale = FALSE, na.action = na.omit)
pred_prova <- predict(svmfit_prova, newdata=matrix_train, decision.values = FALSE)
res_prova <- confusionMatrix(pred_prova, factor(label_train))  
```

```{r svm graph}
w <- t(best_model$coefs) %*% best_model$SV
w <- abs(w)
names_sorted <- best_genes[order(w, decreasing=TRUE)]
print(names_sorted)

# insert the two genes ID printed at the previous line and execute the following line to see the plot
plot(best_model, dataNorm_train, ENSG00000245750~ENSG00000261437, svSymbol = "v")
```

<div style="text-align: justify">
The genes selected as the ones that lead to the best model are now analyze in terms of Gene Ontology, in order to find if they are associated with some important terms related with the colon tumor.
</div>

```{r GO annotations}
alldata <- select(org.Hs.eg.db, best_genes, columns = c("SYMBOL","ENTREZID", 
                  "ENSEMBL","GOALL"), keytype="ENSEMBL")

terms <- unique(alldata[,4])
terms <- terms[!is.na(terms)]

annotation_featuresRFE <- as.data.frame(annotation_terms(vals, terms))
```

<div style="text-align: justify">
The models obtained from the second while cycle are now tested on the test set to see their performances on it and to evaluate if the best model is the best one also in terms of accuracy over the test set.
</div>

```{r accuracies of best models on test set}
accuracy_test <- NULL
par <- NULL
for (i in (1:100)){
  svmfit_prova <- rfe$bests[[i]]
  pred_prova <- predict(svmfit_prova, newdata=dataNorm_test, decision.values = FALSE)
  res_prova <- confusionMatrix(pred_prova, factor(label_test)) 
  accuracy_test <- c(accuracy_test,res_prova[["overall"]][["Accuracy"]])
  par <- c(par,rfe$number_features[i])
}
plot(par,accuracy_test, xlab = "Number of parameters", ylab = "Accuracy over test set")
```



